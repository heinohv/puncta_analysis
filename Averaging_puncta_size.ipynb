{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4MWiwgbrUj-",
        "outputId": "cf62ea36-ece4-4295-acb9-2fe54a04eac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#bring your google drive in and grant colab the ability to read/write \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yRA_szi3rWrV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading in all the functions this code may use\n",
        "def file_name_to_genotype(input_path=str):\n",
        "    \"\"\"\n",
        "    This function will copy text before the first underscore in column 2 and move it to column 1\n",
        "    It will also remove all puncta that have discard set to 1 (this is when FWHM > ROI width)\n",
        "    :param input_path: input a string that contains the path to your input CSV file\n",
        "    :return: a data frame with the above changes made\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path)\n",
        "    file_names = []\n",
        "    for row in range(len(df)):\n",
        "        file_name = df.iloc[row, 1]\n",
        "        if type(file_name) == str:\n",
        "            file_name_split = file_name.split(\"_\")\n",
        "            genotype = file_name_split[0]\n",
        "            df.iloc[row, 0] = genotype\n",
        "        if file_name not in file_names:\n",
        "            file_names.append(file_name)\n",
        "\n",
        "    #removing all data points where discard is not set to 0 (FWHM > ROI width)\n",
        "    df_filt = df.loc[:, \"discard\"] == 0\n",
        "    df = df[df_filt]\n",
        "    return df\n",
        "\n",
        "\n",
        "def make_a_list_of_unique_image_names(data_frame):\n",
        "    \"\"\"\n",
        "    This function will record all unique image names from column #2 in your CSV\n",
        "    :param input_path: input the data frame you want to pull unique images names from (column 2)\n",
        "    :return: returns a list of all unique strings from column 2\n",
        "    \"\"\"\n",
        "    unique_image_names_list = []\n",
        "    df = data_frame\n",
        "    for row in range(len(df)):\n",
        "        image_name = df.iloc[row, 1]\n",
        "        if type(image_name) == str:\n",
        "            if image_name not in unique_image_names_list:\n",
        "                unique_image_names_list.append(image_name)\n",
        "    return unique_image_names_list\n",
        "\n",
        "\n",
        "def average_df(data_frame, output_path, list_of_unique_names):\n",
        "    \"\"\"\n",
        "    This function will find the average values for each unique image name\n",
        "    e.g.\n",
        "\n",
        "    A: 3\n",
        "    A: 2\n",
        "    A: 4\n",
        "    B: 1\n",
        "    B: 2\n",
        "    B: 3\n",
        "     goes to :\n",
        "     A: 3\n",
        "     B: 2\n",
        "    :param data_frame: input the data frame you want to average\n",
        "    :param output_path: input the path/file name you want the averaged CSV to be saved to\n",
        "    :param list_of_unique_names: input a list of all unique image names\n",
        "    \"\"\"\n",
        "    df = data_frame\n",
        "\n",
        "    # making an empty dictionary with a key for each variable/column\n",
        "    averages_dictionary = {}\n",
        "    headers_list = list(df.columns)\n",
        "    for header in headers_list:\n",
        "        averages_dictionary[header] = []\n",
        "\n",
        "    # Create a mini data frame from just one image name at a time (one worm)\n",
        "    for image_name in list_of_unique_names:\n",
        "        df_filt = df.loc[:, \"image_name\"] == image_name\n",
        "        file_name_specific_df = df[df_filt]\n",
        "\n",
        "        # loop through the data frame, calculating the average for each column\n",
        "        for column in range(len(file_name_specific_df.columns)):\n",
        "            mean = 0\n",
        "            for row in range(len(file_name_specific_df)):\n",
        "                cell_value = file_name_specific_df.iloc[row, column]\n",
        "\n",
        "                # taking all numbers and turning them into floats to add them to an average\n",
        "                if isinstance(cell_value, float):\n",
        "                    mean += cell_value/len(file_name_specific_df)\n",
        "                if isinstance(cell_value, np.int64):\n",
        "                    cell_value = float(cell_value)\n",
        "                    mean += cell_value / len(file_name_specific_df)\n",
        "                if isinstance(cell_value, int):\n",
        "                    cell_value = float(cell_value)\n",
        "                    mean += cell_value / len(file_name_specific_df)\n",
        "\n",
        "                # if there is a string, just record the string in place of an average\n",
        "                if isinstance(cell_value, str):\n",
        "                    mean = cell_value\n",
        "\n",
        "            averages_dictionary[headers_list[column]].append(mean)\n",
        "    full_averages_df = pd.DataFrame(averages_dictionary)\n",
        "    full_averages_df.to_csv(output_path, index=False)\n",
        "\n",
        "\n",
        "def make_bar_graph(input_path=str, X=str, Y_variables=list):\n",
        "    \"\"\"\n",
        "    this will make a bargraph with SEM bars for the CSV path you input\n",
        "    :param input_path: input the path to the CSV you want to graph\n",
        "    :param X: Choose the parameter for the x value (e.g. genotype)\n",
        "    :param Y_variables: Input a LIST of parameters you want for the Y axis (e.g. FWHM of the puncta)\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    for Y_variable in Y_variables:\n",
        "        # dictonary to store the data we need for a bar graph\n",
        "        bar_graph_dict = {}\n",
        "\n",
        "        # make a list of unique genotypes so we can average them\n",
        "        unique_genotypes = []\n",
        "        for genotype in df.loc[:, \"genotype\"]:\n",
        "            if genotype not in unique_genotypes:\n",
        "                unique_genotypes.append(genotype)\n",
        "        bar_graph_dict[X] = unique_genotypes\n",
        "\n",
        "        # calculate the averages and stdevs for each genotype, and save them in a list\n",
        "        averages = []\n",
        "        stdevs = []\n",
        "        sems = []\n",
        "        for genotype in unique_genotypes:\n",
        "            df_filt = df.loc[:, \"genotype\"] == genotype\n",
        "            geno_df = df[df_filt]\n",
        "            averages.append(geno_df.loc[:, Y_variable].mean())\n",
        "            stdevs.append(geno_df.loc[:, Y_variable].std())\n",
        "            sems.append(geno_df.loc[:, Y_variable].sem())\n",
        "\n",
        "        bar_graph_dict[Y_variable] = averages\n",
        "        bar_graph_dict[Y_variable + \"Error_bars\"] = sems\n",
        "\n",
        "        bar_graph_df = pd.DataFrame(bar_graph_dict)\n",
        "        print(bar_graph_df)\n",
        "        plt.bar(bar_graph_df['genotype'], bar_graph_df[Y_variable], yerr=bar_graph_df[Y_variable + \"Error_bars\"], capsize=5)\n",
        "        plt.ylabel(Y_variable)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def make_a_swarm_plot(input_path=str, X=str, Y_variables=list):\n",
        "    df = pd.read_csv(input_path)\n",
        "\n",
        "    for Y_variable in Y_variables:\n",
        "        sns.swarmplot(data=df, x=X, y=Y_variable, s=4)\n",
        "        plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NykS8EujsU5F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path assignments\n",
        "CSV_input = \"/content/drive/MyDrive/Puncta_size.csv\"\n",
        "CSV_output = \"/content/drive/MyDrive/Puncta_size_averages.csv\"\n",
        "\n",
        "# Step 1: Pull the genotype from the file name to make stats easier later\n",
        "df = file_name_to_genotype(CSV_input)\n",
        "\n",
        "# Step 2: Make a list of all unique image names in the CSV\n",
        "list_file_names = make_a_list_of_unique_image_names(df)\n",
        "\n",
        "# Step 3: Make a filtered array for each unique file name, and average the data frame for each unique file name as save as csv\n",
        "average_df(df, CSV_output, list_file_names)\n",
        "\n",
        "# Step 4 plot the data (SEM error bars)\n",
        "make_bar_graph(CSV_output, \"genotype\", [\"full_width_half_max_microns\", \"ROI max intensity\"])"
      ],
      "metadata": {
        "id": "I3DlwHhArklj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step ? plot the data (swarm plot)\n",
        "make_a_swarm_plot(CSV_output, \"genotype\", [\"full_width_half_max_microns\", \"ROI max intensity\"])"
      ],
      "metadata": {
        "id": "sUnQcESXDhWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}